{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFFXqcChoSvi"
      },
      "source": [
        "* Groove MIDI Dataset을 이용하여 4마디(bar)에 해당하는 드럼 샘플을 뽑아내기\n",
        " * 미디 데이터? \n",
        "  * 음악이 어떻게 연주되어야 하는지 나타내는 악보!\n",
        "  * 어느 시점에 어떤 악기를 연주하여야 하는지가 나와있는 데이터\n",
        "  * .midi의 확장자명"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz88KexNnyDI"
      },
      "source": [
        "# 0. 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3q3rRgl2WqT",
        "outputId": "083063fb-350e-4dce-bd90-7d341945f024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfggZOeUnsOi",
        "outputId": "ff64d10c-f7b8-4b3f-9c08-922409f3729b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/13/ee/eb8413c7e46f2dc110454e366b3ccf39e6db765749c8daf01a625c33323f/promise-0.2.2.tar.gz#sha256=1fb52a23bee47644819c4a11b0b7169474625c44629f9b76a04cf59e118f4f6c (from https://pypi.org/simple/promise/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/f6/07/fcd91d39d6f80c4c9a314efa28dbff33c91ef9aaf94169bcee09aa70d50f/promise-0.2.1.tar.gz#sha256=edbc51aa90318c9157f980b715e614543c863b86add41be70885c649cceef343 (from https://pypi.org/simple/promise/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/96/22/7ab1480ca9de349c380a4fbdf1a1ebcbfe2adef5a6183a26a0a9d88b8c6c/promise-0.2.0.tar.gz#sha256=bd8c3ed58092547c19bf5d321a5a6eb574e8327ff7c9e7b30b463beb54f5cb84 (from https://pypi.org/simple/promise/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/2c/be/f9e01d392107df0e35f88c1d3ca4d9994a84d962214fe155c72bebe1e851/promise-0.1.0.tar.gz#sha256=c2da3af5f1695077a8c130e5f05f308afae5030343925be2bdc9cffad995d678 (from https://pypi.org/simple/promise/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#@title Setup Environment\n",
        "\n",
        "print('Installing dependencies...')\n",
        "\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -q pyfluidsynth\n",
        "!pip install -U -q magenta\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "# Allow python to pick up the newly-installed fluidsynth lib.\n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "  \n",
        "print('Importing software libraries...')\n",
        "\n",
        "import copy, warnings, librosa, numpy as np\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "\n",
        "# Colab/Notebook specific stuff\n",
        "import IPython.display\n",
        "from IPython.display import Audio\n",
        "from google.colab import files\n",
        "\n",
        "# Magenta specific stuff\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "from magenta.models.music_vae import data\n",
        "import note_seq\n",
        "from note_seq import midi_synth\n",
        "from note_seq.sequences_lib import concatenate_sequences\n",
        "from note_seq.protobuf import music_pb2\n",
        "\n",
        "# Define some functions\n",
        "\n",
        "# If a sequence has notes at time before 0.0, scootch them up to 0\n",
        "def start_notes_at_0(s):\n",
        "  for n in s.notes:\n",
        "    if n.start_time < 0:\n",
        "      n.end_time -= n.start_time\n",
        "      n.start_time = 0\n",
        "  return s\n",
        "\n",
        "def play(note_sequence, sf2_path='Standard_Drum_Kit.sf2'):  \n",
        "  if sf2_path:\n",
        "    audio_seq = midi_synth.fluidsynth(start_notes_at_0(note_sequence), sample_rate=44100, sf2_path=sf2_path)\n",
        "    IPython.display.display(IPython.display.Audio(audio_seq, rate=44100))\n",
        "  else:\n",
        "    note_seq.play_sequence(start_notes_at_0(note_sequence), synth=note_seq.fluidsynth)\n",
        "\n",
        "# Some midi files come by default from different instrument channels\n",
        "# Quick and dirty way to set midi files to be recognized as drums\n",
        "def set_to_drums(ns):\n",
        "  for n in ns.notes:\n",
        "    n.instrument=9\n",
        "    n.is_drum = True\n",
        "    \n",
        "def unset_to_drums(ns):\n",
        "  for note in ns.notes:\n",
        "    note.is_drum=False\n",
        "    note.instrument=0\n",
        "  return ns\n",
        "\n",
        "# quickly change the tempo of a midi sequence and adjust all notes\n",
        "def change_tempo(note_sequence, new_tempo):\n",
        "  new_sequence = copy.deepcopy(note_sequence)\n",
        "  ratio = note_sequence.tempos[0].qpm / new_tempo\n",
        "  for note in new_sequence.notes:\n",
        "    note.start_time = note.start_time * ratio\n",
        "    note.end_time = note.end_time * ratio\n",
        "  new_sequence.tempos[0].qpm = new_tempo\n",
        "  return new_sequence\n",
        "\n",
        "def download(note_sequence, filename):\n",
        "  note_seq.sequence_proto_to_midi_file(note_sequence, filename)\n",
        "  files.download(filename)\n",
        "  \n",
        "def download_audio(audio_sequence, filename, sr):\n",
        "  librosa.output.write_wav(filename, audio_sequence, sr=sr, norm=True)\n",
        "  files.download(filename)\n",
        " \n",
        "# Load some configs to be used later\n",
        "dc_quantize = configs.CONFIG_MAP['groovae_2bar_humanize'].data_converter\n",
        "dc_tap = configs.CONFIG_MAP['groovae_2bar_tap_fixed_velocity'].data_converter\n",
        "dc_hihat = configs.CONFIG_MAP['groovae_2bar_add_closed_hh'].data_converter\n",
        "dc_4bar = configs.CONFIG_MAP['groovae_4bar'].data_converter\n",
        "\n",
        "# quick method for removing microtiming and velocity from a sequence\n",
        "def get_quantized_2bar(s, velocity=0):\n",
        "  new_s = dc_quantize.from_tensors(dc_quantize.to_tensors(s).inputs)[0]\n",
        "  new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
        "  if velocity != 0:\n",
        "    for n in new_s.notes:\n",
        "      n.velocity = velocity\n",
        "  return new_s\n",
        "\n",
        "# quick method for turning a drumbeat into a tapped rhythm\n",
        "def get_tapped_2bar(s, velocity=85, ride=False):\n",
        "  new_s = dc_tap.from_tensors(dc_tap.to_tensors(s).inputs)[0]\n",
        "  new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
        "  if velocity != 0:\n",
        "    for n in new_s.notes:\n",
        "      n.velocity = velocity\n",
        "  if ride:\n",
        "    for n in new_s.notes:\n",
        "      n.pitch = 42\n",
        "  return new_s\n",
        "\n",
        "# quick method for removing hi-hats from a sequence\n",
        "def get_hh_2bar(s):\n",
        "  new_s = dc_hihat.from_tensors(dc_hihat.to_tensors(s).inputs)[0]\n",
        "  new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
        "  return new_s\n",
        "\n",
        "\n",
        "# Calculate quantization steps but do not remove microtiming\n",
        "def quantize(s, steps_per_quarter=4):\n",
        "  return note_seq.sequences_lib.quantize_note_sequence(s,steps_per_quarter)\n",
        "\n",
        "# Destructively quantize a midi sequence\n",
        "def flatten_quantization(s):\n",
        "  beat_length = 60. / s.tempos[0].qpm\n",
        "  step_length = beat_length / 4#s.quantization_info.steps_per_quarter\n",
        "  new_s = copy.deepcopy(s)\n",
        "  for note in new_s.notes:\n",
        "    note.start_time = step_length * note.quantized_start_step\n",
        "    note.end_time = step_length * note.quantized_end_step\n",
        "  return new_s\n",
        "\n",
        "# Calculate how far off the beat a note is\n",
        "def get_offset(s, note_index):\n",
        "  q_s = flatten_quantization(quantize(s))\n",
        "  true_onset = s.notes[note_index].start_time\n",
        "  quantized_onset = q_s.notes[note_index].start_time\n",
        "  diff = quantized_onset - true_onset\n",
        "  beat_length = 60. / s.tempos[0].qpm\n",
        "  step_length = beat_length / 4#q_s.quantization_info.steps_per_quarter\n",
        "  offset = diff/step_length\n",
        "  return offset\n",
        "\n",
        "def is_4_4(s):\n",
        "  ts = s.time_signatures[0]\n",
        "  return (ts.numerator == 4 and ts.denominator ==4)\n",
        "\n",
        "def preprocess_4bar(s):\n",
        "  return dc_4bar.from_tensors(dc_4bar.to_tensors(s).outputs)[0]\n",
        "\n",
        "def preprocess_2bar(s):\n",
        "  return dc_quantize.from_tensors(dc_quantize.to_tensors(s).outputs)[0]\n",
        "\n",
        "def _slerp(p0, p1, t):\n",
        "  \"\"\"Spherical linear interpolation.\"\"\"\n",
        "  omega = np.arccos(np.dot(np.squeeze(p0/np.linalg.norm(p0)),\n",
        "    np.squeeze(p1/np.linalg.norm(p1))))\n",
        "  so = np.sin(omega)\n",
        "  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
        "\n",
        "print('Downloading drum samples...')\n",
        "# Download a drum kit for playing drum midi\n",
        "!gsutil -q -m cp gs://magentadata/soundfonts/Standard_Drum_Kit.sf2 .\n",
        "\n",
        "print(\"Download MIDI data...\")\n",
        "\n",
        "# Load MIDI files from GMD with MIDI only (no audio) as a tf.data.Dataset\n",
        "dataset_2bar = tfds.as_numpy(tfds.load(\n",
        "    name=\"groove/2bar-midionly\",\n",
        "    split=tfds.Split.VALIDATION,\n",
        "    try_gcs=True))\n",
        "\n",
        "dev_sequences = [quantize(note_seq.midi_to_note_sequence(features[\"midi\"])) for features in dataset_2bar]\n",
        "_ = [set_to_drums(s) for s in dev_sequences]\n",
        "dev_sequences = [s for s in dev_sequences if is_4_4(s) and len(s.notes) > 0 and s.notes[-1].quantized_end_step > note_seq.steps_per_bar_in_quantized_sequence(s)]\n",
        "\n",
        "dataset_4bar = tfds.as_numpy(tfds.load(\n",
        "    name=\"groove/4bar-midionly\",\n",
        "    split=tfds.Split.VALIDATION,\n",
        "    try_gcs=True))\n",
        "\n",
        "dev_sequences_4bar = [quantize(note_seq.midi_to_note_sequence(features[\"midi\"])) for features in dataset_4bar]\n",
        "_ = [set_to_drums(s) for s in dev_sequences_4bar]\n",
        "dev_sequences_4bar = [s for s in dev_sequences_4bar if is_4_4(s) and len(s.notes) > 0 and s.notes[-1].quantized_end_step > note_seq.steps_per_bar_in_quantized_sequence(s)]\n",
        "\n",
        "\n",
        "print(\"Loading model checkpoints...\")\n",
        "\n",
        "# Download all the models\n",
        "!gsutil -q -m cp gs://magentadata/models/music_vae/checkpoints/groovae_*.tar .\n",
        "GROOVAE_4BAR = \"groovae_4bar.tar\" # 4-bar groove autoencoder.\n",
        "GROOVAE_2BAR_HUMANIZE = \"groovae_2bar_humanize.tar\"\n",
        "GROOVAE_2BAR_HUMANIZE_NOKL = \"groovae_2bar_humanize_nokl.tar\"\n",
        "GROOVAE_2BAR_HITS_CONTROL = \"groovae_2bar_hits_control.tar\"\n",
        "GROOVAE_2BAR_TAP_FIXED_VELOCITY = \"groovae_2bar_tap_fixed_velocity.tar\"\n",
        "GROOVAE_2BAR_ADD_CLOSED_HH = \"groovae_2bar_add_closed_hh.tar\"\n",
        "GROOVAE_2BAR_HITS_CONTROL_NOKL = \"groovae_2bar_hits_control_nokl.tar\"\n",
        "\n",
        "print(\"Downloading audio data...\")\n",
        "!gsutil -q -m cp gs://magentadata/models/music_vae/groovae_colab/*wav ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1fbWumLp-9L"
      },
      "source": [
        "## 1. 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 직접 전처리"
      ],
      "metadata": {
        "id": "bxOs8hmn6QTe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m80yBKxwoJJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67cf6198-7d80-419c-bffb-2e8bae26b869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.1\n",
            "tfds.core.DatasetInfo(\n",
            "    name='groove',\n",
            "    version=2.0.1,\n",
            "    description='The Groove MIDI Dataset (GMD) is composed of 13.6 hours of aligned MIDI and\n",
            "(synthesized) audio of human-performed, tempo-aligned expressive drumming\n",
            "captured on a Roland TD-11 V-Drum electronic drum kit.',\n",
            "    homepage='https://g.co/magenta/groove-dataset',\n",
            "    features=FeaturesDict({\n",
            "        'bpm': tf.int32,\n",
            "        'drummer': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "        'id': tf.string,\n",
            "        'midi': tf.string,\n",
            "        'style': FeaturesDict({\n",
            "            'primary': ClassLabel(shape=(), dtype=tf.int64, num_classes=18),\n",
            "            'secondary': tf.string,\n",
            "        }),\n",
            "        'time_signature': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),\n",
            "        'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    }),\n",
            "    total_num_examples=21415,\n",
            "    splits={\n",
            "        'test': 2033,\n",
            "        'train': 17261,\n",
            "        'validation': 2121,\n",
            "    },\n",
            "    supervised_keys=None,\n",
            "    citation=\"\"\"@inproceedings{groove2019,\n",
            "        Author = {Jon Gillick and Adam Roberts and Jesse Engel and Douglas Eck and David Bamman},\n",
            "        Title = {Learning to Groove with Inverse Sequence Transformations},\n",
            "        Booktitle\t= {International Conference on Machine Learning (ICML)}\n",
            "        Year = {2019},\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(tfds.__version__)\n",
        "\n",
        "# load data\n",
        "dataset, info = tfds.load(\n",
        "    name=\"groove/4bar-midionly\", #4bar-midionly 데이터 이용\n",
        "    split=tfds.Split.TRAIN,\n",
        "    with_info=True,\n",
        "    try_gcs=True)\n",
        "\n",
        "# Feature \n",
        "print(info) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MeAlEQ3MyEj5"
      },
      "outputs": [],
      "source": [
        "# build input pipeline\n",
        "dataset = dataset.shuffle(1024).batch(32).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE)\n",
        "for features in dataset.take(1):\n",
        "  # Access the features you are interested in\n",
        "  midi, genre = features[\"midi\"], features[\"style\"][\"primary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "u9S5jdwtyOw3"
      },
      "outputs": [],
      "source": [
        "# tfrecord로 저장\n",
        "import pathlib\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\"\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
        "                                   fname='/content/drive/MyDrive/pozalabs', \n",
        "                                   extract=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yEX8xcWeydWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50e8087-5f08-47a7-8c94-9d652afd0b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: convert_dir_to_note_sequences: command not found\n"
          ]
        }
      ],
      "source": [
        "!convert_dir_to_note_sequences \\\n",
        "  --input_dir=/content/drive/MyDrive/pozalabs \\\n",
        "  --output_file=/content/drive/MyDrive/Pozalabs/sequences.tfrecord \\\n",
        "  --recursive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) magenta의 전처리된 코드를 불러오기"
      ],
      "metadata": {
        "id": "qFhdSIAt6VO3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SCUPrpkqBDW"
      },
      "source": [
        "## 2. 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) pre-trained model 사용\n",
        "* 참고 - https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb\n",
        "* groovae_4bar : 4-bar groove autoencoder\n",
        "* full-midionly : groove 전체 데이터셋"
      ],
      "metadata": {
        "id": "Qdx_hs514cei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python music_vae_train.py \\\n",
        "--config=groovae_4bar \\\n",
        "--run_dir=/content/drive/MyDrive/Pozalabs \\\n",
        "--mode=train \\\n",
        "--num_steps=20000 \\\n",
        "--tfds_name=groove/full-midionly \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGSJKGwm1zxL",
        "outputId": "ebd88297-0478-4977-af2e-bb91b7a84c94"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'music_vae_train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) GrooveConverter 클래스\n",
        "* 참고 - https://github.com/magenta/magenta/blob/main/magenta/models/music_vae/data.py"
      ],
      "metadata": {
        "id": "sBKIVBt84ifz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJgqJDKyqCed"
      },
      "source": [
        "## 3. 생성"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "!python music_vae_generate.py \\\n",
        "--config=groovae_4bar \\\n",
        "--checkpoint_file=/content/drive/MyDrive/Pozalabs/groovae_full/train/model.ckpt-##### \\ # loss가 가장 작을 때의 check point 이용\n",
        "--mode=sample \\\n",
        "--num_outputs=5 \\\n",
        "--output_dir=/content/drive/MyDrive/Pozalabs/groovae_full/generated\n",
        "'''"
      ],
      "metadata": {
        "id": "j9a5ZQB73bn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 샘플 확인"
      ],
      "metadata": {
        "id": "DHMwYNan4OzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FypjdHBN4P0H"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Music VAE.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}